{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# Dataset\n",
    "DATASET = 'bloodmnist'\n",
    "NUM_CLASSES = 8\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "#Environment\n",
    "CUDA_SEED = 0\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "LABELS_PER_CLASS = 10\n",
    "LR=.0001\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# Active Learning\n",
    "NUM_ACTIVE_LEARNING_ITERATIONS = 3\n",
    "QUERY_SIZE = NUM_CLASSES * LABELS_PER_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET HANDLING\n",
    "\n",
    "class DataSubset(Dataset):\n",
    "  def __init__(self, base_dataset, inds=None, size=-1):\n",
    "    self.base_dataset = base_dataset\n",
    "    if inds is None:\n",
    "        inds = np.random.choice(\n",
    "            list(range(len(base_dataset))), size, replace=False)\n",
    "    self.inds = inds\n",
    "\n",
    "  def __getitem__(self, ind):\n",
    "    self.base_ind = self.inds[ind]\n",
    "    return self.base_dataset[self.base_ind]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inds)\n",
    "\n",
    "def get_data(train_inds=None, train_labeled_inds=None, train_unlabeled_inds=None, inds_to_query=None, active_learning_iter=False):\n",
    "  def cycle(loader):\n",
    "    while True:\n",
    "      for data in loader:\n",
    "        yield data\n",
    "            \n",
    "  def MedMNIST(train, transforms):\n",
    "    info = INFO[DATASET]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    return DataClass(split='train' if train else 'val', transform=transforms, download=True)\n",
    "  \n",
    "  transform_train = transforms.Compose([\n",
    "    transforms.Pad(4, padding_mode=\"reflect\"),\n",
    "    transforms.RandomCrop(28),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x + 3e-2 * torch.randn_like(x)\n",
    "  ])\n",
    "\n",
    "  transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "    lambda x: x + 3e-2 * torch.randn_like(x)\n",
    "  ])\n",
    "\n",
    "  if not active_learning_iter: # if start iteration\n",
    "    train_class = MedMNIST(train=True, transforms=transform_train) # (img_vector, label)\n",
    "\n",
    "    train_inds = list(range(len(train_class)))\n",
    "    \n",
    "    # np.random.seed(0)\n",
    "    # np.random.shuffle(train_inds)\n",
    "\n",
    "    train_inds = np.array(train_inds)\n",
    "    train_labels = np.array([np.squeeze(train_class[ind][1]) for ind in train_inds])\n",
    "\n",
    "    if NUM_CLASSES > 0:\n",
    "      train_labeled_inds, train_unlabeled_inds = [], []\n",
    "      for i in range(NUM_CLASSES):\n",
    "        train_labeled_inds.extend(train_inds[train_labels == i][:LABELS_PER_CLASS])\n",
    "        train_unlabeled_inds.extend(train_inds[train_labels == i][LABELS_PER_CLASS:])\n",
    "    else:\n",
    "      train_labeled_inds = train_inds\n",
    "\n",
    "    \n",
    "  else: # Every active learning iteration\n",
    "    train_labeled_inds = np.append(train_labeled_inds, inds_to_query)\n",
    "    relative_inds_in_unlabeled_set = np.argwhere(np.isin(train_unlabeled_inds, inds_to_query))\n",
    "    train_unlabeled_inds = np.delete(train_unlabeled_inds, relative_inds_in_unlabeled_set)\n",
    "\n",
    "  dset_train = DataSubset(MedMNIST(train=True, transforms=transform_train), inds=train_inds)\n",
    "  dset_train_labeled = DataSubset(MedMNIST(train=True, transforms=transform_train), inds=train_labeled_inds)\n",
    "  dset_train_unlabeled = DataSubset(MedMNIST(train=True, transforms=transform_train), inds=train_unlabeled_inds)\n",
    "  dset_validation = MedMNIST(train=False, transforms=transform_val)\n",
    "\n",
    "  BATCH_SIZE_LABELED = BATCH_SIZE_UNLABELED = BATCH_SIZE if LABELS_PER_CLASS * NUM_CLASSES > BATCH_SIZE else LABELS_PER_CLASS * NUM_CLASSES\n",
    "\n",
    "  dload_train = DataLoader(dset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "  dload_train_labeled = DataLoader(dset_train_labeled, batch_size=BATCH_SIZE_LABELED, shuffle=True, num_workers=2, drop_last=True)\n",
    "  # dload_train_labeled = cycle(dload_train_labeled)\n",
    "  dload_train_unlabeled = DataLoader(dset_train_unlabeled, batch_size=BATCH_SIZE_UNLABELED, shuffle=True, num_workers=2, drop_last=True)\n",
    "  dload_val = DataLoader(dset_validation, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "  return dload_train, dload_train_labeled, dload_train_unlabeled, dload_val, train_inds, train_labeled_inds, train_unlabeled_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Visualization via t-SNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_dataset(dload_train, sampled_inds=[], show_entire_dataset=False):\n",
    "  input_tensors = []\n",
    "  target_labels = []\n",
    "\n",
    "  for inputs, targets in tqdm(dload_train):\n",
    "    input_tensors.append(inputs)\n",
    "    target_labels.append(targets)\n",
    "\n",
    "  inputs = torch.cat(input_tensors, dim=0)\n",
    "  target_labels = torch.cat(target_labels, dim=0).squeeze().numpy()\n",
    "\n",
    "  num_inputs, _, _, _ = inputs.shape\n",
    "\n",
    "  tsne = TSNE(n_components=2, random_state=0)\n",
    "  embeddings = tsne.fit_transform(inputs.view(num_inputs, -1))\n",
    "\n",
    "  _, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "  if show_entire_dataset:\n",
    "    for i in range(NUM_CLASSES):\n",
    "      embeddings_cluster = embeddings[target_labels == i]\n",
    "      ax.scatter(embeddings_cluster[:, 0], embeddings_cluster[:, 1],label=f\"Class {i}\", s=3)\n",
    "  else:\n",
    "    ax.scatter(embeddings[:, 0], embeddings[:, 1], color='gray', s=3)\n",
    "    embeddings_samples = embeddings[sampled_inds]\n",
    "    ax.scatter(embeddings_samples[:, 0], embeddings_samples[:, 1],label=\"Sampled images\", color='red', s=30)\n",
    "  ax.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/93 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'get_data.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlosgil/Documents/Osaka University/Graduation project/Source Code/Confidence-Callibration/Active Learning.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dload_train, dload_train_labeled, dload_train_unlabeled, dload_val, train_inds, train_labeled_inds, train_unlabeled_inds \u001b[39m=\u001b[39m get_data()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m visualize_dataset(dload_train, sampled_inds\u001b[39m=\u001b[39;49m[], show_entire_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/Users/carlosgil/Documents/Osaka University/Graduation project/Source Code/Confidence-Callibration/Active Learning.ipynb Cell 5\u001b[0m in \u001b[0;36mvisualize_dataset\u001b[0;34m(dload_train, sampled_inds, show_entire_dataset)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m input_tensors \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m target_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m tqdm(dload_train):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   input_tensors\u001b[39m.\u001b[39mappend(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlosgil/Documents/Osaka%20University/Graduation%20project/Source%20Code/Confidence-Callibration/Active%20Learning.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   target_labels\u001b[39m.\u001b[39mappend(targets)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    920\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> 927\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'get_data.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "dload_train, dload_train_labeled, dload_train_unlabeled, dload_val, train_inds, train_labeled_inds, train_unlabeled_inds = get_data()\n",
    "\n",
    "visualize_dataset(dload_train, sampled_inds=[], show_entire_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, in_channels, num_classes):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, 16, kernel_size=3),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(16, 16, kernel_size=3),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(16, 64, kernel_size=3),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(64, 64, kernel_size=3),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer5 = nn.Sequential(\n",
    "      nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Linear(64 * 4 * 4, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "\n",
    "model = Net(in_channels=NUM_CHANNELS, num_classes=NUM_CLASSES)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "dload_train, dload_train_labeled, dload_train_unlabeled, dload_val, train_inds, train_labeled_inds, train_unlabeled_inds = get_data()\n",
    "\n",
    "for al_iter in range(NUM_ACTIVE_LEARNING_ITERATIONS):\n",
    "  print(f'Active Learning iteration #{al_iter}')\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(f'    Epoch #{epoch}')\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for inputs, targets in tqdm(dload_train_labeled):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        targets = targets.squeeze().long()\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "  inds_to_query = np.random.randint(0, len(train_unlabeled_inds), QUERY_SIZE)\n",
    "  dload_train, dload_train_labeled, dload_train_unlabeled, dload_val, train_inds, train_labeled_inds, train_unlabeled_inds = get_data(train_inds=train_inds,\n",
    "                                                                                                                                      train_labeled_inds=train_labeled_inds,\n",
    "                                                                                                                                      train_unlabeled_inds=train_unlabeled_inds,\n",
    "                                                                                                                                      inds_to_query=inds_to_query,\n",
    "                                                                                                                                      active_learning_iter=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "181a558524a3a2a91d0c76313ac1570f0fb272238a8b73e3efbaac1c1ef56039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
