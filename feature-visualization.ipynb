{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: multi-class\n",
      "num_channels: 3\n",
      "num_classes: 8\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"bloodmnist\"\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "dataset_info = INFO[DATASET]\n",
    "task = dataset_info['task']\n",
    "num_channels = dataset_info['n_channels']\n",
    "num_classes = len(dataset_info['label'])\n",
    "\n",
    "DatasetClass = getattr(medmnist, dataset_info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /Users/carlosgil/.medmnist/bloodmnist.npz\n",
      "Dataset BloodMNIST (bloodmnist)\n",
      "    Number of datapoints: 11959\n",
      "    Root location: /Users/carlosgil/.medmnist\n",
      "    Split: train\n",
      "    Task: multi-class\n",
      "    Number of channels: 3\n",
      "    Meaning of labels: {'0': 'basophil', '1': 'eosinophil', '2': 'erythroblast', '3': 'immature granulocytes(myelocytes, metamyelocytes and promyelocytes)', '4': 'lymphocyte', '5': 'monocyte', '6': 'neutrophil', '7': 'platelet'}\n",
      "    Number of samples: {'train': 11959, 'val': 1712, 'test': 3421}\n",
      "    Description: The BloodMNIST is based on a dataset of individual normal cells, captured from individuals without infection, hematologic or oncologic disease and free of any pharmacologic treatment at the moment of blood collection. It contains a total of 17,092 images and is organized into 8 classes. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images with resolution 3×360×363 pixels are center-cropped into 3×200×200, and then resized into 3×28×28.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "dset_train = DatasetClass(split='train', transform=data_transform, download=True)\n",
    "dset_test = DatasetClass(split='test', transform=data_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dload_train = data.DataLoader(dataset=dset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dload_val = data.DataLoader(dataset=dset_train, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "dload_test = data.DataLoader(dataset=dset_test, batch_size=2*BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, in_channels, num_classes):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels, 16, kernel_size=3),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(16, 16, kernel_size=3),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(16, 64, kernel_size=3),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(64, 64, kernel_size=3),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layer5 = nn.Sequential(\n",
    "      nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Linear(64 * 4 * 4, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(in_channels=num_channels, num_classes=num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "181a558524a3a2a91d0c76313ac1570f0fb272238a8b73e3efbaac1c1ef56039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
